<ol><li><strong>Multinomial Logistic Regression:</strong> A statistical model used to predict the probability of an instance belonging to one of three or more classes.<br /></li><li><strong>Confusion Matrix:</strong> A table used to evaluate the performance of a classification model. For multinomial models, it shows the counts of true and predicted classes for each class.<br /></li><li><strong>Multilabel Confusion Matrix:</strong> A confusion matrix specifically designed for multilabel classification problems, where each instance can belong to multiple classes simultaneously.<br /></li><li><strong>Classification Report</strong>: A comprehensive evaluation metric that includes precision, recall, F1-score, and support for each class, as well as overall accuracy and averages.<br /></li><li><strong>Precision:</strong> The proportion of true positive predictions out of all positive predictions for a specific class.<br /></li><li><strong>Recall:</strong> The proportion of true positive predictions out of all actual positive instances for a specific class. Also known as sensitivity.<br /></li><li><strong>F1-Score:</strong> The harmonic mean of precision and recall, providing a balanced measure of a model's performance for a specific class.<br /></li><li><strong>TN (True Negative):</strong> The number of instances correctly predicted as not belonging to a specific class.<br /></li><li><strong>FP (False Positive):</strong> The number of instances incorrectly predicted as belonging to a specific class.<br /></li><li><strong>FN (False Negative):</strong> The number of instances incorrectly predicted as not belonging to a specific class.<br /></li><li><strong>TP (True Positive):</strong> The number of instances correctly predicted as belonging to a specific class.<br /></li><li><strong>Test Statistics:</strong> Evaluation metrics used to assess the performance of a classification model.<br /></li><li><strong>Support:</strong> The number of actual instances belonging to a specific class in the test set.<br /></li></ol>