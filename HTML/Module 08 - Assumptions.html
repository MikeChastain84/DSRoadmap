<p><strong>Linear Regression Assumptions</strong></p><p>The assumptions for linear regression are:</p><ul><li>There is a linear relationship between the dependent variable and the independent variable(s).</li><li>The residuals are normally distributed.</li><li>The variance of the residuals is constant over all values of the independent variable(s) (homoscedasticity).</li><li>The residuals are independent.</li></ul><p>These assumptions are important because they ensure that the results of the regression analysis are valid. If the assumptions are not met, the results of the analysis may be misleading.</p><p><strong>Logistic Regression Assumptions</strong></p><p>Assumptions for Binary Logistic Regression</p><ul><li>Binary Outcome: The dependent variable should be binary (i.e., having only two possible outcomes).</li><li>Linearity of Independent Variables and Log Odds: There should be a linear relationship between the independent variables and the log odds of the dependent variable.</li><li>No Multicollinearity: The independent variables should not be highly correlated with each other.</li><li>Large Sample Size: Logistic regression generally requires a larger sample size compared to linear regression for reliable results.</li><li>Independence of Observations: The observations in the dataset should be independent of each other.</li></ul><p>It's important to note that logistic regression is more robust to violations of some of these assumptions compared to linear regression. However, checking for and addressing potential violations can improve the accuracy and reliability of your results.</p><p><strong>Terms</strong></p><p><strong>General Linear Model</strong></p><ul><li>A statistical model that assumes a linear relationship between the dependent variable and one or more independent variables.<br /></li><li>The basic form is y=β0​+β1​X+e where:<br /><ul><li>y is the dependent variable.</li><li>X is the independent variable.</li><li>β0​ is the intercept.</li><li>β1​ is the slope.</li><li>e is the error term or residual.</li></ul></li></ul><p><strong>Residuals</strong></p><ul><li>The differences between the actual and predicted values of the dependent variable in a regression model.</li></ul><p><strong>Normally Distributed</strong></p><ul><li>A probability distribution that is symmetric and bell-shaped.</li></ul><p><strong>Homoscedasticity</strong></p><ul><li>The variance of the residuals is constant across all levels of the independent variable.</li></ul><p><strong>Independent</strong></p><ul><li>The residuals are not correlated with each other.</li></ul><p><strong>Skewed</strong></p><ul><li>A distribution that is not symmetric.</li></ul><p><strong>Linearity</strong></p><ul><li>A linear relationship between the dependent and independent variables.</li></ul><p><strong>Multi-Collinearity</strong></p><ul><li>Independent variables in a regression model are highly correlated with each other.</li></ul><p><strong>Hypothesis Testing</strong></p><ul><li>A statistical method used to determine whether there is enough evidence to support a claim about a population parameter.</li></ul><p><strong>Correlation</strong></p><ul><li>A statistical measure that describes the strength and direction of the linear relationship between two variables.</li></ul><p><strong>Python</strong></p><ul><li>A high-level, interpreted, general-purpose programming language.</li></ul><p><strong>Pandas</strong></p><ul><li>A Python library used for data manipulation and analysis.</li></ul><p><strong>Seaborn</strong></p><ul><li>A Python library used for data visualization.</li></ul><p><strong>Scikit-learn (sklearn)</strong></p><ul><li>A Python library used for machine learning.</li></ul><p><strong>Train-test Split</strong></p><ul><li>A technique used to split a dataset into training and testing sets.</li></ul><p><strong>Quantiles</strong></p><ul><li>Values that divide a distribution into equal-sized groups.</li></ul><p><strong>Theoretical Quantiles</strong></p><ul><li>Quantiles that are calculated from a theoretical distribution.</li></ul><p><strong>Sample Quantiles</strong></p><ul><li>Quantiles that are calculated from a sample of data.</li></ul><p><strong>Effective Rank</strong></p><ul><li>The number of independent variables in a regression model that are actually contributing to the prediction of the dependent variable.</li></ul><p><strong>Pairplot</strong></p><ul><li>A Seaborn function that creates a grid of scatterplots showing the relationship between all pairs of variables in a dataset. </li></ul>